# Training Arguments
base_model: gpt2
logits_processor: ConstrainedLogitsProcessorWordLevel

### Decoder PARAMETERS ###
num_layers: 1
num_heads: 1
embedding_size: 100
temperature: 1.0
dropout: 0.1
bias: True


### PATH SAMPLING PROCESS ###

max_hop_length: 3
infer_path_length: 9
MAX_PATHS_PER_USER: 1
path_sample_args:
    temporal_causality: False
    strategy: simple-ui
    parallel_max_workers: -1

path_generation_args:
    paths_per_user: 10


additional_feat_suffix: [useremb, entityemb, relationemb]

# To load the pretrained embeddings (Typically from TransE) necessary to score the paths
load_col:
    useremb: [user_embedding_id, user_embedding]
    entityemb: [entity_embedding_id, entity_embedding]
    relationemb: [relation_embedding_id, relation_embedding]

alias_of_user_id: [user_embedding_id]
alias_of_entity_id: [entity_embedding_id]
alias_of_relation_id: [relation_embedding_id]

preload_weight:
  user_embedding_id: user_embedding
  entity_embedding_id: entity_embedding
  relation_embedding_id: relation_embedding
