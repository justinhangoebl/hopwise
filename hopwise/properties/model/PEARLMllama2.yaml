context_length: 9              # (int) Maximum length of the context.
epochs: 30
eval_step: 1
save_dataset: False
save_dataloaders: True
data_path: /home/recsysdatasets
topk: [10]
valid_metric: 'ndcg@10'
train_batch_size: 4096
eval_batch_size: 100
base_model: llama2
# Training Arguments
learning_rate: 1e-5
weight_decay: 0.0

### Decoder PARAMETERS ###

n_layers: 1
n_heads: 4
hidden_size: 256
temperature: 1.0


### PATH SAMPLING PROCESS ###

max_hop_length: 3
infer_path_length: 9
MAX_PATHS_PER_USER: 1
path_sample_args:
    temporal_causality: False
    strategy: simple-ui
    parallel_max_workers: -1

path_generation_args:
    paths_per_user: 10